{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog Vs Cat image classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries"
      ],
      "metadata": {
        "id": "2jvWGbAY7Xw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "PHnw21OM-QnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wcIgtCzr-glY",
        "outputId": "1834d5c4-8bf5-4d95-9260-50b7e7c5c2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lYGEFtuWERZZ",
        "outputId": "f810cc99-4957-4cc5-aba8-1b372ccc3e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing data"
      ],
      "metadata": {
        "id": "7tA1Y0lh-imn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the Training set"
      ],
      "metadata": {
        "id": "ivse1e8i-nYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image augmentation"
      ],
      "metadata": {
        "id": "LKxwlY0n-vBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, ### feature sclaing (converting 0-255 to 0-1)\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/data/dogandcat/training_set',\n",
        "                                                    target_size=(64, 64),#size of input image\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUF6LwWT_MkN",
        "outputId": "b1d5c031-b403-406a-d77d-7a28ac07cdaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Test Set"
      ],
      "metadata": {
        "id": "czW00TpiJKwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/data/dogandcat/test_set',\n",
        "                                            target_size=(64,64),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf2BuA7vJOXQ",
        "outputId": "8909c9e5-6cc6-493a-de11-067976065a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the  CNN"
      ],
      "metadata": {
        "id": "oUiauLFTMg5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "0LDx-y3KMi9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Convolution"
      ],
      "metadata": {
        "id": "VXx5pukuNEIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=35, kernel_size=3, input_shape=(64, 64, 3), activation='relu'))"
      ],
      "metadata": {
        "id": "dWqZlYBJNHgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Pooling"
      ],
      "metadata": {
        "id": "elI9jJNVOP6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2, \n",
        "                                  padding='valid'))### to accomodate extra columns due to stride"
      ],
      "metadata": {
        "id": "Dny-fkCDOVJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2,\n",
        "                                  padding='valid'))"
      ],
      "metadata": {
        "id": "cZkUJS4APIVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening"
      ],
      "metadata": {
        "id": "Gl1qnkj5SD-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "bFfLtgfASdKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fully connected layer creation"
      ],
      "metadata": {
        "id": "dougsm3USoJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "E9jCJr7WSz8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the CNN model"
      ],
      "metadata": {
        "id": "3pID3-q7TYtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling CNN"
      ],
      "metadata": {
        "id": "_Do9VClhUbnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8CQKsSIYUfNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training CNN and evaluating it on Test set"
      ],
      "metadata": {
        "id": "jfG6jyBYU-rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data=test_set, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7YUcgeZVAzx",
        "outputId": "44530621-f85d-4974-bf95-0c09cb9b46b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "250/250 [==============================] - 1098s 4s/step - loss: 0.6812 - accuracy: 0.5704 - val_loss: 0.6634 - val_accuracy: 0.6065\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 44s 176ms/step - loss: 0.6039 - accuracy: 0.6711 - val_loss: 0.6440 - val_accuracy: 0.6560\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 44s 175ms/step - loss: 0.5626 - accuracy: 0.7084 - val_loss: 0.5870 - val_accuracy: 0.7065\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 44s 175ms/step - loss: 0.5386 - accuracy: 0.7244 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 45s 179ms/step - loss: 0.5110 - accuracy: 0.7465 - val_loss: 0.5696 - val_accuracy: 0.7230\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 43s 173ms/step - loss: 0.4917 - accuracy: 0.7602 - val_loss: 0.4996 - val_accuracy: 0.7570\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 44s 174ms/step - loss: 0.4804 - accuracy: 0.7699 - val_loss: 0.5117 - val_accuracy: 0.7590\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.4654 - val_accuracy: 0.7825\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 44s 175ms/step - loss: 0.4480 - accuracy: 0.7911 - val_loss: 0.4774 - val_accuracy: 0.7700\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 44s 176ms/step - loss: 0.4437 - accuracy: 0.7904 - val_loss: 0.4888 - val_accuracy: 0.7665\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 43s 173ms/step - loss: 0.4416 - accuracy: 0.7944 - val_loss: 0.4603 - val_accuracy: 0.7835\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 43s 174ms/step - loss: 0.4225 - accuracy: 0.8050 - val_loss: 0.4543 - val_accuracy: 0.7930\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 0.4179 - accuracy: 0.8029 - val_loss: 0.4478 - val_accuracy: 0.8005\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 0.4082 - accuracy: 0.8110 - val_loss: 0.4543 - val_accuracy: 0.7980\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 44s 176ms/step - loss: 0.3969 - accuracy: 0.8176 - val_loss: 0.4517 - val_accuracy: 0.8005\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 43s 173ms/step - loss: 0.3848 - accuracy: 0.8269 - val_loss: 0.4544 - val_accuracy: 0.8015\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 44s 174ms/step - loss: 0.3830 - accuracy: 0.8255 - val_loss: 0.4437 - val_accuracy: 0.8060\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 43s 173ms/step - loss: 0.3788 - accuracy: 0.8284 - val_loss: 0.4355 - val_accuracy: 0.7955\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 0.3640 - accuracy: 0.8347 - val_loss: 0.4988 - val_accuracy: 0.7895\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 0.3628 - accuracy: 0.8365 - val_loss: 0.4293 - val_accuracy: 0.8140\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 0.3506 - accuracy: 0.8403 - val_loss: 0.4903 - val_accuracy: 0.7955\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 43s 171ms/step - loss: 0.3426 - accuracy: 0.8462 - val_loss: 0.4385 - val_accuracy: 0.8070\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 43s 171ms/step - loss: 0.3316 - accuracy: 0.8543 - val_loss: 0.4707 - val_accuracy: 0.8035\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 44s 176ms/step - loss: 0.3241 - accuracy: 0.8565 - val_loss: 0.4518 - val_accuracy: 0.8105\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 46s 184ms/step - loss: 0.3224 - accuracy: 0.8600 - val_loss: 0.4585 - val_accuracy: 0.8045\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f477406b650>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn.save('/content/drive/MyDrive/dogandcats_classifiaction/dog_and_cat.h5')"
      ],
      "metadata": {
        "id": "Y7HbVQb9YMIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn =tf.keras.models.load_model('/content/drive/MyDrive/dogandcats_classifiaction/dog_and_cat.h5')"
      ],
      "metadata": {
        "id": "eeSPCm7xY6kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making a prediction"
      ],
      "metadata": {
        "id": "bRbMtktZV0oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/data/dogandcat/single_prediction/IMG_20210116_141329.jpg', \n",
        "                            target_size=(64, 64))"
      ],
      "metadata": {
        "id": "g8YjoZK2V-I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = image.img_to_array(test_image)#creating numpy array\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result = cnn.predict(test_image/255.0)\n",
        "if result[0][0]<=0.5:\n",
        "  prediction = 'Cat'\n",
        "else:\n",
        "  prediction = 'Dog'\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efoNFKzjXQTo",
        "outputId": "972b7ed0-d2ce-46f8-d30e-0cc228085b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_set.class_indices"
      ],
      "metadata": {
        "id": "Y52rCG6ucmyE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "4a89a73b-1feb-412f-bfd0-6e10d4cf34fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8becf6d95625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'training_set' is not defined"
          ]
        }
      ]
    }
  ]
}